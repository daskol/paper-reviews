# Overcoming catastrophic forgetting in neural networks

***Kirkpatrick J. et al, 2017***

Пожалуй, главная ценность статьи заключается в том, что авторы проводят параллели между глубинным обучением и нейробиологией в проблеме катастрофического забывания(catastrofic forgetting problem).
Авторы замечают, что согласно некоторым нейробиологическим представлениям каждый синапс в мозге млекопитающего несёт не только силу связи, но и кодирует её вариацию в амплитуде постсинаптического возбуждения.

Такая мотивация позволила предложить адаптивный регуляризатор, который управлял бы скоростью обучения(learning rate) каждой скрытой переменной.
Адаптивность заключается же в том, что скорость обучения обратно пропорциональна вариации весов.

Предложенный Elastic Weight Consolidation(EWC) регуляризатор может быть обоснован байесовским рассуждением.
Пусть есть последовательность различных задач.
Тогда MAP-оценка параметров на следующей задаче модифицируется таким образом, что априорные вероятности весов заменяются оценкой, полученной на предыдущей задаче.
Предполагая i.i.d. для весов, получаем квадратичный по весам регуляризатор EWC, пропорциональный диагональной матрице Фишера.

По существу регуляризатор пинит(pin) веса в некоторых точках и ограничивает градиенты весов.
Мне кажется, что аналитическая форма функции потерь напоминает лагранжиан в модели Гинзбурга-Ландау.
Учитывая комментарий, о том, как работают на этих задачах L2 регуляризатор можно сделать вывод о том, что создаются "долины", так что часть модели оказывается в равновесии.
Кажется, можно проверить этот факт, разбив L2 регуляризатор на два с различными весами.
Вообще говоря, такой подход напоминает построение минимальной модели нейросети, способной классифицировать MNIST, а EWC регуляризатор способ покомпактнее упаковать несколько моделей вместе.

В работе описано два эксперимента: обучение с учителем на MNIST, где после каждой задачи все пиксели изображения случайно переставлялись; и агент для игр Atari.
Первый эксперимент показал, что EWC заметно выигрывает, и что похожесть информационность матриц сравнивается при углублении сети.
Во втором эксперимменте DQN-агенту случайно подавали десять различных игр с повторением, на которых агент показывает неплохие результаты.

Авторы надеятся, их работа поможет пролить свет как на устройство человеческого мозга, так и на конструктивный подход в построении AI.
